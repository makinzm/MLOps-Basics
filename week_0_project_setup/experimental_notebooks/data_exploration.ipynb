{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Purpose\n",
    "## Author: Nozomi Maki\n",
    "### Date: 26th March 2023\n",
    "\n",
    "- I wanna understand how to use libraries used on this notebook\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Updating Python Library Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: transformers 4.27.3\n",
      "Uninstalling transformers-4.27.3:\n",
      "  Successfully uninstalled transformers-4.27.3\n",
      "Found existing installation: datasets 2.10.1\n",
      "Uninstalling datasets-2.10.1:\n",
      "  Successfully uninstalled datasets-2.10.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: You are using pip version 22.0.4; however, version 23.0.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mCPU times: user 604 ms, sys: 252 ms, total: 855 ms\n",
      "Wall time: 18.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "! pip uninstall transformers datasets -y \n",
    "! pip install transformers datasets -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.21 s, sys: 544 ms, total: 4.75 s\n",
      "Wall time: 4.66 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import datasets\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "# Because of the Occorence of Error in trying to use tokenizer.decode\n",
    "\"\"\"\n",
    "\n",
    "File /usr/local/lib/python3.8/site-packages/transformers/utils/generic.py:98, in _is_torch(x)\n",
    "     97 def _is_torch(x):\n",
    "---> 98     import torch\n",
    "    100     return isinstance(x, torch.Tensor)\n",
    "\n",
    "File /usr/local/lib/python3.8/site-packages/torch/__init__.py:457\n",
    "    443         raise ImportError(textwrap.dedent('''\n",
    "    444             Failed to load PyTorch C extensions:\n",
    "    445                 It appears that PyTorch has loaded the `torch/_C` folder\n",
    "   (...)\n",
    "    453                 or by running Python from a different directory.\n",
    "    454             ''').strip()) from None\n",
    "    455     raise  # If __file__ is not None the cause is unknown, so just re-raise.\n",
    "--> 457 for name in dir(_C):\n",
    "    458     if name[0] != '_' and not name.endswith('Base'):\n",
    "    459         __all__.append(name)\n",
    "\n",
    "NameError: name '_C' is not defined\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "- Official Documentation : [Loading a Dataset](https://huggingface.co/docs/datasets/v1.11.0/loading_datasets.html)\n",
    "\n",
    "    - [datasets/glue # cola](https://huggingface.co/datasets/glue#cola)\n",
    "    - According to this article, cola of glue datasets have the feature wheter each document is glamatically correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset glue (/root/.cache/huggingface/datasets/glue/cola/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78caa873dd5848588a2480520313ed8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 875 ms, sys: 246 ms, total: 1.12 s\n",
      "Wall time: 6.62 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "cola_dataset = load_dataset('glue', 'cola')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Check some versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: datasets\r\n",
      "Version: 2.10.1\r\n",
      "Summary: HuggingFace community-driven open-source library of datasets\r\n",
      "Home-page: https://github.com/huggingface/datasets\r\n",
      "Author: HuggingFace Inc.\r\n",
      "Author-email: thomas@huggingface.co\r\n",
      "License: Apache 2.0\r\n",
      "Location: /usr/local/lib/python3.8/site-packages\r\n",
      "Requires: aiohttp, dill, fsspec, huggingface-hub, multiprocess, numpy, packaging, pandas, pyarrow, pyyaml, requests, responses, tqdm, xxhash\r\n",
      "Required-by: \r\n"
     ]
    }
   ],
   "source": [
    "! pip show datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: transformers\n",
      "Version: 4.27.3\n",
      "Summary: State-of-the-art Machine Learning for JAX, PyTorch and TensorFlow\n",
      "Home-page: https://github.com/huggingface/transformers\n",
      "Author: The Hugging Face team (past and future) with the help of all our contributors (https://github.com/huggingface/transformers/graphs/contributors)\n",
      "Author-email: transformers@huggingface.co\n",
      "License: Apache 2.0 License\n",
      "Location: /usr/local/lib/python3.8/site-packages\n",
      "Requires: filelock, huggingface-hub, numpy, packaging, pyyaml, regex, requests, tokenizers, tqdm\n",
      "Required-by: \n",
      "CPU times: user 177 ms, sys: 105 ms, total: 283 ms\n",
      "Wall time: 5.42 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "! pip show transformers "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence', 'label', 'idx'],\n",
       "        num_rows: 8551\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['sentence', 'label', 'idx'],\n",
       "        num_rows: 1043\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentence', 'label', 'idx'],\n",
       "        num_rows: 1063\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cola_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = cola_dataset['train']\n",
    "val_dataset = cola_dataset['validation']\n",
    "test_dataset = cola_dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8551, 1043, 1063)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset), len(val_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence': \"Our friends won't buy this analysis, let alone the next one we propose.\",\n",
       " 'label': 1,\n",
       " 'idx': 0}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'sentence': 'The sailors rode the breeze clear of the rocks.',\n",
       " 'label': 1,\n",
       " 'idx': 0}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'sentence': 'Bill whistled past the house.', 'label': -1, 'idx': 0}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(\n",
    "    train_dataset[0],\n",
    "    val_dataset[0],\n",
    "    test_dataset[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence': Value(dtype='string', id=None),\n",
       " 'label': ClassLabel(names=['unacceptable', 'acceptable'], id=None),\n",
       " 'idx': Value(dtype='int32', id=None)}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- About filter functions: https://huggingface.co/docs/datasets/v1.1.1/package_reference/main_classes.html#datasets.Dataset.filter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/glue/cola/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-8bed84235e43dc0a.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'sentence': [\"Our friends won't buy this analysis, let alone the next one we propose.\",\n",
       "  \"One more pseudo generalization and I'm giving up.\",\n",
       "  \"One more pseudo generalization or I'm giving up.\",\n",
       "  'The more we study verbs, the crazier they get.',\n",
       "  'Day by day the facts are getting murkier.'],\n",
       " 'label': [1, 1, 1, 1, 1],\n",
       " 'idx': [0, 1, 2, 3, 4]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.filter(\n",
    "    lambda example: \n",
    "        example['label'] == train_dataset.features['label'].str2int('acceptable')\n",
    "    )[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "ClassLabel(names=['unacceptable', 'acceptable'], id=None)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'sentence': Value(dtype='string', id=None),\n",
       " 'label': ClassLabel(names=['unacceptable', 'acceptable'], id=None),\n",
       " 'idx': Value(dtype='int32', id=None)}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['sentence', 'label', 'idx'],\n",
       "    num_rows: 8551\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(\n",
    "    train_dataset.features['label'].str2int('acceptable'),\n",
    "    train_dataset.features['label'],\n",
    "    train_dataset.features,\n",
    "    train_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/glue/cola/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-f819639e03f8949a.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'sentence': ['They drank the pub.',\n",
       "  'The professor talked us.',\n",
       "  'We yelled ourselves.',\n",
       "  'We yelled Harry hoarse.',\n",
       "  'Harry coughed himself.'],\n",
       " 'label': [0, 0, 0, 0, 0],\n",
       " 'idx': [18, 20, 22, 23, 25]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.filter(\n",
    "    lambda example: \n",
    "        example['label'] == train_dataset.features['label'].str2int('unacceptable')\n",
    "    )[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 248 ms, sys: 53.3 ms, total: 301 ms\n",
      "Wall time: 332 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 266 ms, sys: 49.7 ms, total: 315 ms\n",
      "Wall time: 4.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/bert_uncased_L-2_H-128_A-2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = cola_dataset['train']\n",
    "val_dataset = cola_dataset['validation']\n",
    "test_dataset = cola_dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertTokenizerFast(name_or_path='google/bert_uncased_L-2_H-128_A-2', vocab_size=30522, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our friends won't buy this analysis, let alone the next one we propose.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 2256, 2814, 2180, 1005, 1056, 4965, 2023, 4106, 1010, 2292, 2894, 1996, 2279, 2028, 2057, 16599, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_dataset[0]['sentence'])\n",
    "tokenizer(train_dataset[0]['sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our our our fire T our GTGTG T\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 2256, 2256, 2256, 2543, 1056, 2256, 14181, 13512, 2290, 1056, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_temp_sentences = \"Our our our fire T our GTGTG T\"\n",
    "print(_temp_sentences)\n",
    "tokenizer(_temp_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 1.56 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"[CLS] our friends won't buy this analysis, let alone the next one we propose. [SEP]\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tokenizer.decode(tokenizer(train_dataset[0]['sentence'])['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(examples):\n",
    "    return tokenizer(\n",
    "            examples[\"sentence\"],\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=512,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8551 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset = train_dataset.map(encode, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.38 ms, sys: 162 Âµs, total: 3.55 ms\n",
      "Wall time: 3.78 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0,\n",
       "         1, 0, 0, 1, 1, 1, 1, 1]),\n",
       " 'input_ids': tensor([[  101,  2256,  2814,  ...,     0,     0,     0],\n",
       "         [  101,  2028,  2062,  ...,     0,     0,     0],\n",
       "         [  101,  2028,  2062,  ...,     0,     0,     0],\n",
       "         ...,\n",
       "         [  101,  5965, 12808,  ...,     0,     0,     0],\n",
       "         [  101,  2198, 10948,  ...,     0,     0,     0],\n",
       "         [  101,  3021, 24471,  ...,     0,     0,     0]]),\n",
       " 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0]])}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([32, 512]) torch.Size([32, 512]) torch.Size([32])\n",
      "torch.Size([7, 512]) torch.Size([7, 512]) torch.Size([7])\n",
      "CPU times: user 1.11 s, sys: 21.6 ms, total: 1.13 s\n",
      "Wall time: 1.13 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for batch in dataloader:\n",
    "    print(batch['input_ids'].shape, batch['attention_mask'].shape, batch['label'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
